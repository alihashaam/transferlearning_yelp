{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is for selecting domain O and D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firstly, we will analyse what data we have *-Caution: Python 2.7 is used!-*\n",
    "- This step, let's load businesses CSV file to discern what categories are there in YELP R10 data\n",
    "    - After some time, I discovered that the categories aren't a list of lists, but of **strings**! -_-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Addiction Medicine': 7, u'& Probates': 37, u'Acai Bowls': 37, u'3D Printing': 5, u'Accessories': 1600, u'Active Life': 7427, u'Accountants': 214, u'Acupuncture': 503, u'Acne Treatment': 11, u'ATV Rentals/Tours': 40}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import ast; #import the abstracr syntax trees library, to evaluate the string of multiple categories\n",
    "#from ggplot import *; #https://github.com/yhat/ggpy for documentation\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "businessesFilePath = \"/media/sog/Data/College/DKEM/3_WS_17_18/Team Project YELP SA/dataset/business.csv\";\n",
    "dfBusinesses = pd.read_csv(businessesFilePath,\n",
    "                          usecols=['business_id','categories'],\n",
    "                          engine='python');\n",
    "\n",
    "#Take a look at what we have in there:\n",
    "#print dfBusinesses.head();\n",
    "\n",
    "#Deceptively enough, categories is of type string, not list, so we need to convert it to strings\n",
    "dictCategories = {};\n",
    "for categoryRecord in dfBusinesses[\"categories\"]:\n",
    "    lstCategories = ast.literal_eval(categoryRecord);\n",
    "    for cat in lstCategories:\n",
    "        dictCategories[cat] = dictCategories.get(cat,0) + 1;\n",
    "        \n",
    "#Let's have a look at 10 elements:\n",
    "print {k: dictCategories[k] for k in sorted(dictCategories.keys())[:10]};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to perform a group count for the categories, to get an insight of businesses tallies. Thank God we don't have arbitrary nesting, otherwise we would need to flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Frequency\n",
      "Restaurants           51613\n",
      "Shopping              24595\n",
      "Food                  23014\n",
      "Beauty & Spas         15139\n",
      "Home Services         13202\n",
      "Health & Medical      12033\n",
      "Nightlife             11364\n",
      "Bars                   9868\n",
      "Automotive             9476\n",
      "Local Services         9343\n"
     ]
    }
   ],
   "source": [
    "#Convert the dictionary to a DataFrame\n",
    "dfCategories = pd.DataFrame.from_dict(dictCategories, orient=\"index\");\n",
    "dfCategories.columns = [\"Frequency\"];\n",
    "dfCategories = dfCategories.sort_values(by=\"Frequency\",ascending=False);\n",
    "\n",
    "print dfCategories.head(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's calculate the percentage of these businesses' types according to the total number of businesses, keeping in mind that a certain entity may be ascribed to more than 1 category, so it's not a 1-1 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of business entities: 156639\n",
      "\n",
      "                           Frequency  Category_Total_pct\n",
      "Restaurants                    51613            0.329503\n",
      "Shopping                       24595            0.157017\n",
      "Food                           23014            0.146924\n",
      "Beauty & Spas                  15139            0.096649\n",
      "Home Services                  13202            0.084283\n",
      "Health & Medical               12033            0.076820\n",
      "Nightlife                      11364            0.072549\n",
      "Bars                            9868            0.062998\n",
      "Automotive                      9476            0.060496\n",
      "Local Services                  9343            0.059647\n",
      "Event Planning & Services       8038            0.051315\n",
      "Active Life                     7427            0.047415\n"
     ]
    }
   ],
   "source": [
    "#Add the percentage of occurences of a category in the whole dataset\n",
    "print \"Total number of business entities: \" + str(dfBusinesses.shape[0]) + \"\\n\";\n",
    "dfCategories[\"Category_Total_pct\"] = dfCategories[\"Frequency\"] / dfBusinesses.shape[0];\n",
    "#List the first 1% of business by number of ocurrence\n",
    "print dfCategories.head(int(0.01 * dfCategories.shape[0]));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first rule to pick the categories, we want to exclude the ones that describe less than 5% of all entities, assuming that their datasets sizes aren't encouraging to adopt them as candidates for domain O, or even D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Frequency  Category_Total_pct\n",
      "Restaurants                    51613            0.329503\n",
      "Shopping                       24595            0.157017\n",
      "Food                           23014            0.146924\n",
      "Beauty & Spas                  15139            0.096649\n",
      "Home Services                  13202            0.084283\n",
      "Health & Medical               12033            0.076820\n",
      "Nightlife                      11364            0.072549\n",
      "Bars                            9868            0.062998\n",
      "Automotive                      9476            0.060496\n",
      "Local Services                  9343            0.059647\n",
      "Event Planning & Services       8038            0.051315\n"
     ]
    }
   ],
   "source": [
    "#Picking the ones whose pct is >= 5%\n",
    "dfCandidateCategories = dfCategories[dfCategories[\"Category_Total_pct\"] >= 0.0500];\n",
    "print dfCandidateCategories;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have now to *merge* between the business entities which correspond to one of these categories and the reviews, in order to analyse the number of reviews as a crucial factor in choosing our domains\n",
    "    - Since we are dealing with strings in categories, we have to build a unicode filter vector, as follows (more on this [Here](https://stackoverflow.com/questions/11350770/pandas-dataframe-select-by-partial-string\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Restaurants|Shopping|Food|Beauty & Spas|Home Services|Health & Medical|Nightlife|Bars|Automotive|Local Services|Event Planning & Services\n",
      "\n",
      "11 business categories to be considered:\n",
      "\n",
      "---------------\n",
      "\n",
      "\n",
      "After filtering, 156639 out of 156639 business entities left (100%).\n",
      "\n",
      "              business_id                                         categories\n",
      "0  YDf95gJZaq05wvo7hTQbbQ                 [u'Shopping', u'Shopping Centers']\n",
      "1  mLwM-h2YhXl2NCgdS84_Bw  [u'Food', u'Soul Food', u'Convenience Stores',...\n",
      "2  v2WhjAB3PIBA8J8VxG3wEg                         [u'Food', u'Coffee & Tea']\n",
      "3  CVtCbSB1zUcUWg-9TNGTuQ         [u'Professional Services', u'Matchmakers']\n",
      "4  duHFBe87uNSXImQmvBh87Q                    [u'Sandwiches', u'Restaurants']\n"
     ]
    }
   ],
   "source": [
    "#Build the filter from our candidate categories:\n",
    "unicodeFilter = \"\";\n",
    "\n",
    "\n",
    "for cat in dfCandidateCategories.index:\n",
    "    unicodeFilter += \"|\" + str(cat);\n",
    "    \n",
    "    \n",
    "print str(unicodeFilter) + \"\\n\\n\" + str(dfCandidateCategories.shape[0]) \\\n",
    "+ \" business categories to be considered:\\n\\n---------------\\n\\n\"\n",
    "\n",
    "\n",
    "dfCandidateBusinessesIds = dfBusinesses.loc[dfBusinesses[\"categories\"].str.contains(unicodeFilter)];\n",
    "\n",
    "\n",
    "print \"After filtering, \" + str(dfCandidateBusinessesIds.shape[0]) + \" out of \" \\\n",
    "+ str(dfBusinesses.shape[0]) + \" \" \\\n",
    "\"business entities left (\"+ str(100*dfCandidateBusinessesIds.shape[0]/dfBusinesses.shape[0]) +\"%).\\n\";\n",
    "\n",
    "\n",
    "print dfCandidateBusinessesIds.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It appears that the candidate categories cover the **whole dataset**! I think that's a *good* thing..\n",
    "    - so let's split the businesses data to extract merge vectors of each category, in order to get the relevant number of reviews we have later on\n",
    "        - Splitting was done in pure code rather than the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrafeatures(rows, columns, increment_at_step):\n",
    "    \"\"\"create sparse matrix of the given size with zero as all elements\"\"\"\n",
    "    extra_Features = sparse.csr_matrix(np.zeros([rows,0])) # sparse.csr_matrix(np.zeros([170623,0]))\n",
    "    iter_columns = 0\n",
    "    while extra_Features.shape[1] < columns:\n",
    "        if (extra_Features.shape[1] + increment_at_step) > columns:\n",
    "            iter_columns = columns - extra_Features.shape[1]\n",
    "        else:\n",
    "            iter_columns = increment_at_step\n",
    "        extra_Features = hstack((extra_Features,sparse.csr_matrix(np.zeros([rows,iter_columns])))) #[170623,5138]\n",
    "        print \"Columns appended: \"+ str(extra_Features.shape[1])\n",
    "    return extra_Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Pure CountVectorizers from Pickle files -> with pure, we mean related to only one business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_counts_restaurents = joblib.load('count_vectorizers/baseline_restaurants_x.pkl')\n",
    "X_train_counts_bars = joblib.load('count_vectorizers/baseline_Bars_x.pkl')\n",
    "X_train_counts_home_services = joblib.load('count_vectorizers/baseline_Home Services_x.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurents vs Bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Features_Stats.pynb we got the information that we need to append 34493 features to Restaurents sparse document term matrix and appned 528023 features to bars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_features_against_bars = extrafeatures(2927730, 34493, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528023\n"
     ]
    }
   ],
   "source": [
    "bars_features_against_restaurents = extrafeatures(942711, 528023, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the extrafeatures to the respective sparse matrix(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_features_against_bars = hstack((X_train_counts_restaurents, restaurent_features_against_bars))\n",
    "joblib.dump(restaurent_features_against_bars, 'count_vectorizers/baseline_RESTAURENTS_x_bars.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_vectorizers/baseline_BARS_x_restaurents.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars_features_against_restaurents = hstack((X_train_counts_bars, bars_features_against_restaurents))\n",
    "joblib.dump(bars_features_against_restaurents, 'count_vectorizers/baseline_BARS_x_restaurents.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restautrents vs Home Services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Features_Stats.pynb we got the information that we need to append 44626 features to Restaurents sparse document term matrix and appned 852908 features to Home Services. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_features_against_hs = extrafeatures(2927730, 44626, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_features_against_restaurents = extrafeatures(170623, 852908, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the extrafeatures to the respective sparse matrix(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurent_features_against_hs = hstack((X_train_counts_restaurents, restaurent_features_against_hs))\n",
    "joblib.dump(restaurent_features_against_hs, 'count_vectorizers/baseline_RESTAURENTS_x_homeservices.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['count_vectorizers/baseline_HOMESERVICES_x_restaurents.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_features_against_restaurents = hstack((X_train_counts_home_services, hs_features_against_restaurents))\n",
    "joblib.dump(hs_features_against_restaurents, 'count_vectorizers/baseline_HOMESERVICES_x_restaurents.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurents_bars_baseline = joblib.load('count_vectorizers/baseline_RESTAURENTS_x_bars.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2927730x951620 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 140659190 stored elements in COOrdinate format>,\n",
       " <2927730x917127 sparse matrix of type '<type 'numpy.int64'>'\n",
       " \twith 140659190 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurents_bars_baseline, X_train_counts_restaurents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that now the extra features has been appended but number of stored elements remain the same and that is what was required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_restaurents_baseline = joblib.load('count_vectorizers/baseline_BARS_x_restaurents.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<942711x951620 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 46649986 stored elements in COOrdinate format>,\n",
       " <942711x423597 sparse matrix of type '<type 'numpy.int64'>'\n",
       " \twith 46649986 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_restaurents_baseline, X_train_counts_bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurents_hs_baseline = joblib.load('count_vectorizers/restaurents vs home services/baseline_RESTAURENTS_x.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<2927730x961753 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 140659190 stored elements in COOrdinate format>,\n",
       " <2927730x917127 sparse matrix of type '<type 'numpy.int64'>'\n",
       " \twith 140659190 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurents_hs_baseline, X_train_counts_restaurents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_restaurents_baseline = joblib.load('count_vectorizers/restaurents vs home services/baseline_HOMESERVICES_x.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<170623x961753 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 8205924 stored elements in COOrdinate format>,\n",
       " <170623x108845 sparse matrix of type '<type 'numpy.int64'>'\n",
       " \twith 8205924 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_restaurents_baseline, X_train_counts_home_services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "haha = [[['haha', 'this', 'is', 'the', 'best' , 'day', 'ever', 'this']],\n",
    "        [['this', 'is', 'the', 'best', 'date', 'ever']],\n",
    "        [['worst', 'time', 'to', 'be', 'alive']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame(data=haha, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[haha, this, is, the, best, day, ever, this]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, is, the, best, date, ever]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[worst, time, to, be, alive]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text\n",
       "0  [haha, this, is, the, best, day, ever, this]\n",
       "1             [this, is, the, best, date, ever]\n",
       "2                  [worst, time, to, be, alive]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectss = CountVectorizer(lowercase=False, preprocessor = lambda x:x, tokenizer= lambda text:text)\n",
    "X_train_countsssss = count_vectss.fit_transform(main_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 13)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_countsssss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = count_vectss.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.extend([\"abc\", \"haha\", \"etty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in xrange(0,3):\n",
    "    X_train_countsssss = hstack((X_train_countsssss,np.array([0,0,0])[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alive  be  best  date  day  ever  haha  is  the  this  time  to  worst  abc  haha  etty\n",
      "0      0   0     1     0    1     1     1   1    1     2     0   0      0    0     0     0\n",
      "1      0   0     1     1    0     1     0   1    1     1     0   0      0    0     0     0\n",
      "2      1   1     0     0    0     0     0   0    0     0     1   1      1    0     0     0\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(X_train_countsssss.A, columns=abc).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
